{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L22AYve6NHZN",
        "outputId": "a9b04353-50a1-4dc8-b091-14645e43111a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    print(\"GPU is not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SAlNHNygE1K",
        "outputId": "2d73810e-2a20-4207-e5eb-fcd1c320a01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.0\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/'\n",
        "import zipfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-pT0O7pNV2B",
        "outputId": "fb79933f-0076-4924-ea6d-f583d769c101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1699556619213.jpg\n",
            " 1699556619225.jpg\n",
            "'1 Million Subscribers Gift - BMBULLS'\n",
            " 22CH10084_Assign_1_TC.pdf\n",
            " 22CH10084_practice_sheet_TC.pdf\n",
            " aagaz\n",
            "'American Expres Campus Challenge 2024'\n",
            "'AMEX features doc.gdoc'\n",
            " Answer_doc.gdoc\n",
            " assign5_22CH10084.pdf\n",
            "'batsman level.gsheet'\n",
            "'CDC Intern 2023'\n",
            "'Colab Notebooks'\n",
            " Cold_mailing_phand.gsheet\n",
            "'Copy of AHCM-HealthSocialNeedsScreeningTool-rev-8_10_2021.pdf'\n",
            "'Copy of Gmail Sheets mail merge  (10).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (11).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (12).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (13).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (14).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (15).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (16).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (17).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (18).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (19).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (1).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (20).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (21).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (22).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (23).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (24).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (2).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (3).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (4).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (5).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (6).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (7).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (8).gsheet'\n",
            "'Copy of Gmail Sheets mail merge  (9).gsheet'\n",
            "'Copy of Gmail Sheets mail merge .gsheet'\n",
            "'Copy of Health Leads Screening_Toolkit_2018.pdf'\n",
            "'Copy of PRAPARE-English.pdf'\n",
            "'Copy of PRAPARE-Risk-Tally-Score-Quick-Sheet-1 (1).pdf'\n",
            "'Copy of PRAPARE-Risk-Tally-Score-Quick-Sheet-1.pdf'\n",
            "'Coursera 3XY3M9Z5JTHV.pdf'\n",
            " csv_zip.zip\n",
            "'CV _ SyedWasiq (1).pdf'\n",
            "'CV_Syed_Wasiq (1).pdf'\n",
            "'CV _ SyedWasiq (2).pdf'\n",
            "'CV _ SyedWasiq.pdf'\n",
            "'CV _ wasiq2 (1).pdf'\n",
            "'CV _ wasiq2.pdf'\n",
            "'CV_Wasiq_Overleaf (1).pdf'\n",
            " CV-Wasiq.pdf\n",
            " data_comments.zip\n",
            " Data_CV.pdf\n",
            "'Eid '\n",
            " Emailed_Fins_2024.pptx\n",
            "'Emailed_Heat Exchanger_2024.pptx'\n",
            " epistemic_emotions_detection_syedwasiq\n",
            " Ftp_undertaking.pdf\n",
            "'fuel lab.pdf'\n",
            " gc\n",
            "'Group 13 Visual Communication(HS30066) Project Report .gdoc'\n",
            " iim2.gsheet\n",
            "'iim projects.gsheet'\n",
            " IMG_1063.HEIC\n",
            " IMG_1121.HEIC\n",
            " IMG_1122.HEIC\n",
            " IMG_1123.HEIC\n",
            " IMG_1124.HEIC\n",
            "'intern assignment'\n",
            "'intern projects'\n",
            "'internship list.gsheet'\n",
            " invoice-template-Aditi.pdf\n",
            " Lab\n",
            " lab_test_2_dataset.zip\n",
            "'Legal Confidentiality Agreement.pages'\n",
            "'match level.gsheet'\n",
            "'May trek'\n",
            " MLFA_6.ipynb\n",
            " MYCV.pdf\n",
            " my_list.gsheet\n",
            " ntu_frames2.zip\n",
            " ntu_frames.zip\n",
            " ntu.gsheet\n",
            " Quicklution\n",
            " SatyamaroraCV.gdoc\n",
            " SatyamaroraCV.pdf\n",
            " Shoaib\n",
            " Shumail\n",
            " Snapchat-140776623.mp4\n",
            " Snapchat-1846780616.mp4\n",
            " Snapchat-379109003.mp4\n",
            "'survey data.gsheet'\n",
            " TC_Asgn7_solution.pdf\n",
            " TC_Assign-3_22CH10084.pdf\n",
            " TC-assign-4.pdf\n",
            " TC_assign6.pdf\n",
            " TC_practice_problem_5_22CH10084.pdf\n",
            " TC_practice-sheet-3_22CH10084.pdf\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled folder'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet (2).gsheet'\n",
            "'Untitled spreadsheet (3).gsheet'\n",
            "'Untitled spreadsheet (4).gsheet'\n",
            "'Untitled spreadsheet (5).gsheet'\n",
            "'Untitled spreadsheet (6).gsheet'\n",
            "'Untitled spreadsheet (7).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " VID-20231029-WA0010.mp4\n",
            " VID-20231030-WA0000.mp4\n",
            "'VID-20231031-WA0002 (1).mp4'\n",
            " VID-20231031-WA0002.mp4\n",
            " VID-20231031-WA0010.mp4\n",
            " VID-20231031-WA0014.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import zipfile\n",
        "\n",
        "# Path to the zipped folders\n",
        "zip_file1 = '/content/drive/My Drive/ntu_frames2.zip'\n",
        "zip_file2 = '/content/drive/My Drive/ntu_frames.zip'\n",
        "# Extract folder1\n",
        "with zipfile.ZipFile(zip_file1, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/folder1')\n",
        "\n",
        "# Extract folder1\n",
        "with zipfile.ZipFile(zip_file2, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/folder1')\n"
      ],
      "metadata": {
        "id": "Imm19Q1bNk6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file3= '/content/drive/My Drive/csv_zip.zip'\n",
        "with zipfile.ZipFile(zip_file3, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/folder3')\n"
      ],
      "metadata": {
        "id": "Hy8h2QFHN2wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "metadata": {
        "id": "OrXF76-gYjSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_frames_and_ratings(data_folders, csv_folder, target_size=(64, 64), num_frames=5):\n",
        "    data = []\n",
        "    all_ratings = []\n",
        "\n",
        "    for data_folder in data_folders:\n",
        "        subfolders = [f for f in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, f))]\n",
        "\n",
        "        for subfolder in subfolders:\n",
        "            subfolder_path = os.path.join(data_folder, subfolder)\n",
        "            csv_file_name = '_'.join(subfolder.split('_')[1:3]) + '_VideoNumberStartEndRatings.csv'\n",
        "            csv_file = os.path.join(csv_folder, csv_file_name)\n",
        "\n",
        "            if os.path.exists(csv_file):\n",
        "                ratings_df = pd.read_csv(csv_file)\n",
        "\n",
        "                for frames_folder_name in os.listdir(subfolder_path):\n",
        "                    frames_folder_path = os.path.join(subfolder_path, frames_folder_name)\n",
        "                    frame_files = sorted([f for f in os.listdir(frames_folder_path) if f.endswith('.jpg')])\n",
        "                    video_num = int(frames_folder_name.split('_')[-1])\n",
        "                    video_num_padded = str(video_num).zfill(2)\n",
        "                    row = ratings_df[ratings_df['Videonum'] == video_num_padded]\n",
        "\n",
        "                    if not row.empty:\n",
        "                        rating = [\n",
        "                            row['surpriseRate'].values[0],\n",
        "                            row['curiosityRate'].values[0],\n",
        "                            row['confusionRate'].values[0]\n",
        "                        ]\n",
        "\n",
        "                        # Calculate the subsample rate to get exactly num_frames frames\n",
        "                        subsample_rate = max(len(frame_files) // num_frames, 1)\n",
        "                        selected_frames = []\n",
        "\n",
        "                        for i, filename in enumerate(frame_files):\n",
        "                            if i % subsample_rate == 0:\n",
        "                                img = load_img(os.path.join(frames_folder_path, filename), target_size=target_size)\n",
        "                                img_array = img_to_array(img) / 255.0  # Convert to RGB and normalize\n",
        "                                selected_frames.append(img_array)\n",
        "                            if len(selected_frames) == num_frames:\n",
        "                                break\n",
        "\n",
        "                        # If the number of selected frames is less than num_frames, pad with zeros\n",
        "                        while len(selected_frames) < num_frames:\n",
        "                            selected_frames.append(np.zeros((target_size[0], target_size[1], 3)))\n",
        "\n",
        "                        # Stack arrays to ensure homogeneous shape\n",
        "                        if selected_frames:\n",
        "                            data.append(np.stack(selected_frames))  # Stack to ensure homogeneous shape\n",
        "                            all_ratings.append(np.array(rating))\n",
        "\n",
        "    return np.array(data), np.array(all_ratings)"
      ],
      "metadata": {
        "id": "TFjBEWafW9ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folders = ['/content/folder1/ntu_frames','/content/folder1/ntu_frames2']\n",
        "csv_folder = '/content/folder3/csv'\n",
        "frames_data, ratings_data = load_frames_and_ratings(data_folders, csv_folder)\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train, validation, and test sets\n",
        "train_frames, test_frames, train_ratings, test_ratings = train_test_split(frames_data, ratings_data, test_size=0.2, random_state=42)\n",
        "train_frames, val_frames, train_ratings, val_ratings = train_test_split(train_frames, train_ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Train frames shape: {train_frames.shape}')\n",
        "print(f'Train ratings shape: {train_ratings.shape}')\n",
        "print(f'Validation frames shape: {val_frames.shape}')\n",
        "print(f'Validation ratings shape: {val_ratings.shape}')\n",
        "print(f'Test frames shape: {test_frames.shape}')\n",
        "print(f'Test ratings shape: {test_ratings.shape}')"
      ],
      "metadata": {
        "id": "gtLnugiFYCof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36743591-4721-49ab-8b13-c98dadfb21a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train frames shape: (628, 5, 64, 64, 3)\n",
            "Train ratings shape: (628, 3)\n",
            "Validation frames shape: (158, 5, 64, 64, 3)\n",
            "Validation ratings shape: (158, 3)\n",
            "Test frames shape: (197, 5, 64, 64, 3)\n",
            "Test ratings shape: (197, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "T2G3D2JF9nBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856782ff-9be6-479f-d764-7ec6d38b3e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Configure TensorFlow to use the GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"GPU is available and configured for use\")\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU.\")"
      ],
      "metadata": {
        "id": "PQnSVeKv9u-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1a69d6-6281-4532-f54a-043bafac2e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and configured for use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "SlBQAzKy9z5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_input = Input(shape=(5, 64, 64, 3), name='frame_input')"
      ],
      "metadata": {
        "id": "NRJc8jVY4Mqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, Layer, Conv3D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Enable mixed precision training\n",
        "from tensorflow.keras.mixed_precision import global_policy, set_global_policy, Policy\n",
        "policy = Policy('mixed_float16')\n",
        "set_global_policy(policy)\n",
        "\n",
        "class CustomVGG16(Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomVGG16, self).__init__()\n",
        "        self.vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.vgg16(inputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return self.vgg16.output_shape\n",
        "\n",
        "# Apply the CustomVGG16 layer\n",
        "vgg16_features = CustomVGG16()(frame_input)\n",
        "\n",
        "# Flatten the output from VGG16\n",
        "flattened_features = tf.keras.layers.Flatten()(vgg16_features)\n",
        "x = LSTM(64, return_sequences=False)(flattened_features)\n",
        "# Add Dense layers\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Define the outputs\n",
        "surprise_output = Dense(1, activation='linear', name='surprise_output')(x)\n",
        "curiosity_output = Dense(1, activation='linear', name='curiosity_output')(x)\n",
        "confusion_output = Dense(1, activation='linear', name='confusion_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=frame_input, outputs=[surprise_output, curiosity_output, confusion_output])\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss={'surprise_output': 'mse',\n",
        "                        'curiosity_output': 'mse',\n",
        "                        'confusion_output': 'mse'},\n",
        "                  loss_weights={'surprise_output': 1.0,\n",
        "                                'curiosity_output': 1.0,\n",
        "                                'confusion_output': 1.0})\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "t208Jpy5TAP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras.layers import Bidirectional, Dropout\n",
        "\n",
        "# Define frame input with shape (num_frames, height, width, channels)\n",
        "frame_input = Input(shape=(5, 64, 64, 3), name='frame_input')\n",
        "\n",
        "# Use ResNet50 without the top classification layer\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Apply ResNet50 to each frame using TimeDistributed\n",
        "cnn_features = TimeDistributed(resnet_model)(frame_input)\n",
        "\n",
        "# Step 2: Flatten the output from MobileNetV2\n",
        "flattened_features = TimeDistributed(Flatten())(cnn_features)\n",
        "\n",
        "# Step 3: Use a GRU layer to model temporal dependencies across frames\n",
        "x =LSTM(64, return_sequences=False)(flattened_features)\n",
        "\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "# Step 5: Define the output layers for surprise, curiosity, and confusion\n",
        "surprise_output = Dense(1, activation='linear', name='surprise_output')(x)\n",
        "curiosity_output = Dense(1, activation='linear', name='curiosity_output')(x)\n",
        "confusion_output = Dense(1, activation='linear', name='confusion_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=frame_input, outputs=[surprise_output, curiosity_output, confusion_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'surprise_output': 'mse',\n",
        "                    'curiosity_output': 'mse',\n",
        "                    'confusion_output': 'mse'})\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "nDfORFlX9vzC",
        "outputId": "b14fffa9-25b8-45a5-ab9e-158f226b5814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_34 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_14                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m20,024,384\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_15                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m327,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_14                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_15                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,352,579\u001b[0m (77.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,352,579</span> (77.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,352,579\u001b[0m (77.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,352,579</span> (77.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and capture the history\n",
        "with tf.device('/GPU:0'):\n",
        "    history = model.fit(train_frames,\n",
        "                        [train_ratings[:, 0], train_ratings[:, 1], train_ratings[:, 2]],\n",
        "                        batch_size=32,\n",
        "                        epochs=20,\n",
        "                        validation_data=(val_frames, [val_ratings[:, 0], val_ratings[:, 1], val_ratings[:, 2]]))\n",
        "\n",
        "# Extract training and validation loss from history\n",
        "train_loss = history.history['loss']  # Overall training loss\n",
        "val_loss = history.history['val_loss']  # Overall validation loss\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Overall Training and Validation Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c9Z5RyxDnFDi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "4546f47f-1809-44a3-ac25-dafe74912063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node compile_loss/mse/sub defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [32] vs. [32,3]\n\t [[{{node compile_loss/mse/sub}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_662379[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_662612]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-0199b1e337aa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the model and capture the history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     history = model.fit(train_frames,\n\u001b[0m\u001b[1;32m      6\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/mse/sub defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [32] vs. [32,3]\n\t [[{{node compile_loss/mse/sub}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_662379[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_662612]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions and true ratings to binary based on the threshold\n",
        "threshold = 3\n",
        "surprise_pred_binary = (surprise_pred > threshold).astype(int)\n",
        "curiosity_pred_binary = (curiosity_pred > threshold).astype(int)\n",
        "confusion_pred_binary = (confusion_pred > threshold).astype(int)\n",
        "\n",
        "surprise_true_binary = (test_ratings[:, 0] > threshold).astype(int)\n",
        "curiosity_true_binary = (test_ratings[:, 1] > threshold).astype(int)\n",
        "confusion_true_binary = (test_ratings[:, 2] > threshold).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "surprise_precision = precision_score(surprise_true_binary, surprise_pred_binary, average='macro')\n",
        "surprise_recall = recall_score(surprise_true_binary, surprise_pred_binary, average='macro')\n",
        "surprise_accuracy = accuracy_score(surprise_true_binary, surprise_pred_binary)\n",
        "\n",
        "curiosity_precision = precision_score(curiosity_true_binary, curiosity_pred_binary, average='macro')\n",
        "curiosity_recall = recall_score(curiosity_true_binary, curiosity_pred_binary, average='macro')\n",
        "curiosity_accuracy = accuracy_score(curiosity_true_binary, curiosity_pred_binary)\n",
        "\n",
        "confusion_precision = precision_score(confusion_true_binary, confusion_pred_binary, average='macro')\n",
        "confusion_recall = recall_score(confusion_true_binary, confusion_pred_binary, average='macro')\n",
        "confusion_accuracy = accuracy_score(confusion_true_binary, confusion_pred_binary)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Surprise - Precision: {surprise_precision}, Recall: {surprise_recall}, Accuracy: {surprise_accuracy}\")\n",
        "print(f\"Curiosity - Precision: {curiosity_precision}, Recall: {curiosity_recall}, Accuracy: {curiosity_accuracy}\")\n",
        "print(f\"Confusion - Precision: {confusion_precision}, Recall: {confusion_recall}, Accuracy: {confusion_accuracy}\")"
      ],
      "metadata": {
        "id": "agYXW9GonIjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08057ff-9f2d-4193-813a-a23c9aabccea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Surprise - Precision: 0.5808854831843338, Recall: 0.5805938494167551, Accuracy: 0.5634517766497462\n",
            "Curiosity - Precision: 0.6352398910538446, Recall: 0.635609243697479, Accuracy: 0.6243654822335025\n",
            "Confusion - Precision: 0.5992638980443858, Recall: 0.5987431693989071, Accuracy: 0.5634517766497462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2VChkRLGnUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}